---

# ğŸ¦ **Loan Default Prediction â€“ End-to-End ML & MLOps Project**

This project builds an end-to-end **Loan Default Prediction** system, covering:

âœ” Data cleaning & preprocessing
âœ” Exploratory Data Analysis (EDA)
âœ” Feature engineering
âœ” Handling imbalanced datasets
âœ” Model training & evaluation
âœ” Model explainability (SHAP)
âœ” MLflow experiment tracking & model registry
âœ” System architecture design for production deployment
âœ” Presentation deck summarizing the results

The goal is to develop a **production-ready, fully governed, explainable ML solution** to estimate the probability of loan default for a financial institution.

---

## ğŸ“‚ **Repository Structure**

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/          # Raw data (not versioned in repo)
â”‚   â”œâ”€â”€ raw/                # Cleaned & transformed datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-Preprocessing.ipynb
â”‚   â”œâ”€â”€ 02-Feature_Analysis-Transformations.ipynb
â”‚   â”œâ”€â”€ 03-Model_Development.ipynb
|   |â”€â”€ 04-ML-flow-Training.ipynb
â”‚
â”œâ”€â”€ System Architecture.svg        # System architecture diagram
â”œâ”€â”€ Fraud Detection Presentation.pptx
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

# ğŸš€ **1. Problem Statement**

Financial institutions need reliable mechanisms to **predict loan default risk**.
Traditional rule-based methods struggle with:

* Nonlinear borrower behavior
* Interactions between demographic & financial features
* Missing or incomplete credit history
* Imbalanced data (rare defaulters)

This project develops a **high-performance ML model** to score borrowers and assist credit underwriting, early warning systems, and risk monitoring.

---

# ğŸ§¹ **2. Data Cleaning & Preprocessing**

Key steps:

### âœ” Missing Value Handling

* `<4%` missing: **median** for numeric, **mode** for categorical
* High-missing columns: added indicator flags (e.g., `Score_Source_1_missing`)

### âœ” Outlier & Skewness Handling

* Binning: `Own_House_Age â†’ Own_House_Age_bin`
* Log transform planned for extremely skewed features

### âœ” Categorical Cleaning

* Standardized gender (removed `XNA`)
* Encoded binary variables as category type

### âœ” Mixed Data Types

Fixed columns that had mixed numeric+string values.

### âœ” Final Dataset

Saved to:

```
data/processed/train.csv
data/processed/val.csv
data/processed/test.csv
```

---

# ğŸ” **3. Exploratory Data Analysis (EDA)**

### âœ” Univariate analysis

* Distribution study for numeric & categorical variables
* Detected skewness, outliers, and rare categories
* Identified variable cardinality

### âœ” Bivariate analysis

* Default rate across categorical variables
* Correlation heatmaps
* Feature-wise AUC tests to evaluate predictive power

### âœ” Key EDA Findings

* Credit bureau scores (1/2/3) are strongest predictors
* High loan amount & annuity = higher risk
* Younger borrowers show higher default tendencies
* Employment duration strongly reduces risk

---

# ğŸ›  **4. Feature Engineering**

Implemented:

* Label encoding for categorical features
* Binning (`Own_House_Age`)
* Missing value indicators
* Feature-type separation (numeric vs categorical)
* Stratified train/val/test split (70/15/15)

No scaling needed for tree models.

---

# ğŸ¤– **5. Modeling & Model Selection**

Models trained:

| Model               | AUC   | Recall | F1    | Recall @ Top 5% |
| ------------------- | ----- | ------ | ----- | --------------- |
| Logistic Regression | Low   | Low    | Low   | 0.10            |
| Decision Tree       | ~0.70 | 0.59   | 0.24  | 0.19            |
| **XGBoost**         | 0.75  | 0.84   | 0.21  | 0.21            |
| **LightGBM (Best)** | 0.755 | 0.841  | 0.216 | 0.208           |

### ğŸ“Œ Final Choice: **LightGBM**

Because of:

* Highest AUC
* Strong recall for defaulters
* Stable behavior
* Excellent SHAP explainability
* Fastest inference time

---

# ğŸ” **6. Model Explainability (SHAP)**

### âœ” Global Interpretability

Top contributors to default risk:

1. **Score_Source_3**
2. **Score_Source_2**
3. **Score_Source_1**
4. **Credit_Amount**
5. **Employment Days**
6. **Client Education**
7. **Age Days**
8. **Loan Annuity**

### âœ” Local Explanation

Waterfall plots describe **why** a borrower is predicted as high risk.

SHAP ensures **governance, fairness, and audit readiness**, crucial for banking.

---

# ğŸ“Š **7. MLflow Tracking & Model Registry**

### Logged via MLflow:

* Metrics (AUC, Recall, F1, Accuracy)
* Parameters
* Artifacts (plots, datasets)
* Requirement files & environment

### Registry:

* Best model registered under

  ```
  models:/LoanDefaultModel/
  ```
* Versioning
* Promotion workflow (Staging â†’ Production)

### Loaded model:

```python
loaded = mlflow.pyfunc.load_model("models:/LoanDefaultModel/Production")
preds = loaded.predict(X_test)
```

---

# ğŸ— **8. System Architecture (MLOps Pipeline)**

Architecture file included: **`architecture.svg`**

Key components:

* Data ingestion (API Gateway / batch)
* Data lake (S3)
* Feature Store (Feast)
* MLflow tracking + registry
* Training pipeline (Airflow/Kubeflow)
* Serving (FastAPI / KServe / SageMaker)
* Monitoring (Prometheus, Grafana, Evidently)
* Canary deployments + automatic rollback
* CI/CD (GitHub Actions + ArgoCD)

---

# ğŸ” **9. Security & Governance Practices**

* End-to-end encryption (TLS + AES256)
* PII masking/tokenization
* Role-based access control (IAM + RBAC)
* Model signing + lineage tracking
* Drift detection & fairness monitoring
* Compliance: RBI Fair Lending, GDPR, Responsible AI
* Audit trails via MLflow & Data Catalog

---

# ğŸ§ª **10. How to Run**

### Install dependencies

```bash
pip install -r requirements.txt
```

### Run EDA

Open:

```
notebooks/01-Preprocessing.ipynb
notebooks/02-Feature_Analysis-Transformations.ipynb
```

### Train models

```
notebooks/03-Model_Development.ipynb
```

### MLflow tracking + registry

```
notebooks/04-ML-flow-Training.ipynb
```

---

# ğŸ“ˆ **11. Results Summary**

* Achieved **AUC ~0.755**
* High **recall** for capturing defaulters (**~0.20**)
* Strong **SHAP explainability** ensures transparency
* Deployment-ready architecture included
* MLflow ensures full traceability and governance

---

# ğŸ“– **12. Presentation**

A polished PowerPoint summarizing the project is included:

```
Fraud Detection Presentation.pptx
```

---

# ğŸ™Œ **13. Acknowledgements**

This project demonstrates:

* End-to-end DS workflow
* Real-world MLOps practices
* Enterprise-grade ML governance
* Production readiness

---
